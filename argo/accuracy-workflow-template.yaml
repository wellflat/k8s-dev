apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: accuracy-workflow-template
spec:
  entrypoint: benchmark-lifecycle
  templates:
    - name: benchmark-lifecycle
      dag:
        tasks:
          - name: inference-accuracy-task
            template: lighteval-template
            arguments:
              parameters:
                - name: model-id
                  value: "{{workflow.parameters.model-id}}"
                - name: task
                  value: "{{workflow.parameters.task}}"
          - name: collect-artifacts-task
            template: collect-artifacts-template
            dependencies: [inference-accuracy-task]
    
    - name: lighteval-template
      inputs:
        parameters:
          - name: model-id
          - name: task
        artifacts:
          - name: lighteval-config
            path: /etc/lighteval/config.yaml
            raw:
              data: |
                model_parameters:
                  model_name: "{{inputs.parameters.model-id}}"
                  generation_parameters:
                    temperature: 1.0 
                    max_new_tokens: 16384
                    top_p: 1.0 
                    top_k: 50
                    min_p: 0.0 
                    seed: 12345
                    repetition_penalty: 1.0 
                    frequency_penalty: 0.0
      container:
        image: wellflat/lighteval:latest
        resources:
          limits:
            cpu: 8
            nvidia.com/gpu: 1
          requests:
            cpu: 8
            nvidia.com/gpu: 1
        volumeMounts:
          - name: hf-data
            mountPath: /root/.cache/huggingface/hub
          - name: lighteval-data
            mountPath: /root/.cache/huggingface/lighteval
        env:
          - name: NVIDIA_VISIBLE_DEVICES
            value: all
          - name: NVIDIA_DRIVER_CAPABILITIES
            value: all
          - name: ARTIFACT_BASE_DIR
            value: /root/.cache/huggingface/lighteval/benchmark_results
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-token-secret
                key: hf_token
        command: ["/bin/bash", "-c"]
        args:
          - |
            lighteval accelerate /etc/lighteval/config.yaml \
            "{{inputs.parameters.task}}" \
            --output-dir ${ARTIFACT_BASE_DIR}/{{workflow.uid}}  
      outputs:
        artifacts:
          - name: benchmark-results
            path: /root/.cache/huggingface/lighteval/benchmark_results/{{workflow.uid}}
            archive:
              none: { }
      volumes:
        - name: hf-data
          persistentVolumeClaim:
            claimName: hf-data-pvc
        - name: lighteval-data
          persistentVolumeClaim:
            claimName: lighteval-data-pvc

    - name: collect-artifacts-template
      #inputs:
      #  artifacts:
        # This will be a collection of all artifacts generated by the parallel genai-perf-sweep steps.
      #    - name: benchmark-results
      #      path: /tmp/results # The artifacts will be placed in this directory
      container:
        image: wellflat/hf-dataloader:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            echo "--- Collected benchmark artifacts are available ---"
            ls -R /root/.cache/huggingface/lighteval/benchmark_results
            echo "--- End of artifact list ---"
        volumeMounts:
          - name: lighteval-data
            mountPath: /root/.cache/huggingface/lighteval
        env:
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-token-secret
                key: hf_token
      volumes:
        # This volume mount is kept from the original template in case you need to
        # interact with other cached models within this step.
        - name: lighteval-data
          persistentVolumeClaim:
            claimName: lighteval-data-pvc