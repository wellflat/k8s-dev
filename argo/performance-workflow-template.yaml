apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: performance-workflow-template
spec:
  serviceAccountName: workflow-sa
  entrypoint: benchmark-lifecycle
  templates:
    - name: benchmark-lifecycle
      inputs:
        parameters:
          - name: model-id
          - name: concurrency
          - name: output_token_mean
          - name: request_count
      dag:
        tasks:
          - name: genai-perf-profile
            template: genai-perf-profile-template
            arguments:
              parameters:
                - name: model-id
                  value: "{{inputs.parameters.model-id}}"
                - name: output_token_mean
                  value: "{{inputs.parameters.output_token_mean}}"
                - name: concurrency
                  value: "{{inputs.parameters.concurrency}}"
                - name: request_count
                  value: "{{inputs.parameters.request_count}}"
          - name: get-workflow-info
            template: get-workflow-info-template
            dependencies: [genai-perf-profile]
          - name: collect-artifacts
            template: collect-artifacts-template
            dependencies: [genai-perf-profile]
    
    - name: genai-perf-profile-template
      inputs:
        parameters:
          - name: model-id
          - name: output_token_mean
          - name: concurrency
          - name: request_count
        artifacts:
          - name: genai-perf-config
            path: /root/genai_perf_config.yaml
            raw:
              data: |
                model_names: "{{inputs.parameters.model-id}}"
                endpoint:
                  type: chat
                  streaming: true
                  url: "http://vllm-service:80"
                  server_metrics_url: "http://dcgm-exporter.prometheus.svc.cluster.local:9400/metrics"
                perf_analyzer:
                  stimulus: {'concurrency': "{{inputs.parameters.concurrency}}"}
                  stability_percentage: 999
                  verbose: true
                  warmup_request_count: 10
                  measurement:
                    mode: request_count
                    num: {{inputs.parameters.request_count}}
                input:
                  num_dataset_entries: 200
                  random_seed: 42
                  synthetic_tokens:
                    mean: 200
                    stddev: 30
                  output_tokens:
                    mean: {{inputs.parameters.output_token_mean}}
                    stddev: 30
                output:
                  artifact_directory: "/root/.cache/huggingface/hub/benchmark_results/genai-perf/{{workflow.uid}}/{{inputs.parameters.model-id}}"          
      container:
        image: nvcr.io/nvidia/tritonserver:25.07-py3-sdk
        resources:
          limits:
            nvidia.com/gpu: 1
          requests:
            nvidia.com/gpu: 1
        volumeMounts:
          - name: hf-data
            mountPath: /root/.cache/huggingface/hub
        env:
          - name: NVIDIA_VISIBLE_DEVICES
            value: all
          - name: NVIDIA_DRIVER_CAPABILITIES
            value: all
          - name: ARTIFACT_BASE_DIR
            value: /root/.cache/huggingface/hub/benchmark_results/genai-perf
        command: ["/bin/bash", "-c"]
        args:
          - |
            cat /root/genai_perf_config.yaml
            genai-perf config -f /root/genai_perf_config.yaml
      outputs:
        artifacts:
          - name: benchmark-results
            # This path MUST match the --artifact-dir used in the genai-perf command above.
            path: /root/.cache/huggingface/hub/benchmark_results/genai-perf/{{workflow.uid}}/{{inputs.parameters.model-id}}
            archive:
              none: { }
      volumes:
        - name: hf-data
          persistentVolumeClaim:
            claimName: hf-data-pvc

    - name: get-workflow-info-template
      container:
        image: wellflat/get-workflow:latest
        command: [sh, -c]
        args: [get_workflow_app]
        env:
          - name: IN_CLUSTER_CONFIG
            value: "true"
          - name: WORKFLOW_NAMESPACE
            value: "{{workflow.namespace}}"
          - name: WORKFLOW_NAME
            value: "{{workflow.name}}"
    - name: collect-artifacts-template
      #inputs:
      #  artifacts:
        # This will be a collection of all artifacts generated by the parallel genai-perf-sweep steps.
      #    - name: benchmark-results
      #      path: /tmp/results # The artifacts will be placed in this directory
      container:
        image: wellflat/hf-dataloader:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            echo "--- Collected benchmark artifacts are available ---"
            ls -R /root/.cache/huggingface/hub/benchmark_results/genai-perf
            echo "--- End of artifact list ---"
            # You can add commands here to upload the results to a repository.
            # e.g., huggingface-cli upload my-benchmark-results-repo /tmp/results --repo-type dataset
        volumeMounts:
          - name: hf-data
            mountPath: /root/.cache/huggingface/hub
        env:
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-token-secret
                key: hf_token
      volumes:
        - name: hf-data
          persistentVolumeClaim:
            claimName: hf-data-pvc